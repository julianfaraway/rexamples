---
title: Crossed Effects Design
author: "[Julian Faraway](https://julianfaraway.github.io/)"
date: "`r format(Sys.time(), '%d %B %Y')`"
format: 
  gfm:
    toc: true
---

```{r}
#| label: global_options
#| include: false
knitr::opts_chunk$set(comment=NA, 
                      echo = TRUE,
                      fig.path="figs/",
                      dev = 'svglite',  
                      fig.ext = ".svg",
                      warning=FALSE, 
                      message=FALSE)
knitr::opts_knit$set(global.par = TRUE)
```

```{r}
#| label: graphopts
#| include: false
par(mgp=c(1.5,0.5,0), mar=c(3.1,3.1,0.1,0), pch=20)
ggplot2::theme_set(ggplot2::theme_bw())
```

See the [introduction](index.md) for an overview. 

This example is discussed in more detail in my book
[Extending the Linear Model with R](https://julianfaraway.github.io/faraway/ELM/)

Required libraries:

```{r}
library(faraway)
library(ggplot2)
library(lme4)
library(pbkrtest)
library(RLRsim)
library(INLA)
library(knitr)
library(cmdstanr)
register_knitr_engine(override = FALSE)
library(brms)
library(mgcv)
```

# Data

Effects are said to be crossed when they are
not nested. When at least some crossing occurs, methods for nested
designs cannot be used. We consider a latin square example.

In an experiment, four materials, A, B,
C and D, were fed into a wear-testing machine. The response is the
loss of weight in 0.1 mm over the testing period. The machine could
process four samples at a time and past experience indicated that
there were some differences due to the position of these four samples.
Also some differences were suspected from run to run. Four runs were made. The latin
square structure of the design may be observed:

```{r}
data(abrasion, package="faraway")
matrix(abrasion$material,4,4)
```

We can plot the data

```{r}
#| label: abrasionplot
ggplot(abrasion,aes(x=material, y=wear, shape=run, color=position))+geom_point(position = position_jitter(width=0.1, height=0.0))
```

# Mixed Effect Model

Since we are most interested in the choice of material, treating this as
a fixed effect is natural. We must account for variation due to the
run and the position but were not interested in their specific values
because we believe these may vary between experiments. We treat these
as random effects.

```{r}
mmod <- lmer(wear ~ material + (1|run) + (1|position), abrasion)
faraway::sumary(mmod)
```

We test the random effects:

```{r}
mmodp <- lmer(wear ~ material + (1|position), abrasion)
mmodr <- lmer(wear ~ material + (1|run), abrasion)
exactRLRT(mmodp, mmod, mmodr)
exactRLRT(mmodr, mmod, mmodp)
```

We see both are statistically significant. 


We can test the fixed effect:

```{r}
mmod <- lmer(wear ~ material + (1|run) + (1|position), abrasion,REML=FALSE)
nmod <- lmer(wear ~ 1+ (1|run) + (1|position), abrasion,REML=FALSE)
KRmodcomp(mmod, nmod)
```

We see the fixed effect is significant.

We can compute confidence intervals for the parameters:

```{r}
#| label: abraconfint
#| cache: true
confint(mmod, method="boot")
```

The lower ends of the confidence intervals for the random effect SDs are zero (or close).


# INLA

Integrated nested Laplace approximation is a method of Bayesian computation
which uses approximation rather than simulation. More can be found
on this topic in [Bayesian Regression Modeling with INLA](http://julianfaraway.github.io/brinla/) and the 
[chapter on GLMMs](https://julianfaraway.github.io/brinlabook/chaglmm.html)

Use the most recent computational methodology:


```{r}
inla.setOption(inla.mode="experimental")
inla.setOption("short.summary",TRUE)
```

```{r}
#| label: abrainladef
#| cache: true
formula <- wear ~ material + f(run, model="iid") + f(position, model="iid")
result <- inla(formula, family="gaussian", data=abrasion)
summary(result)
```

The run and position precisions look far too high. Need to change the default prior.

## Informative Gamma priors on the precisions

Now try more informative gamma priors for the random effect precisions. Define it so
the mean value of gamma prior is set to the inverse of the variance of
the residuals of the fixed-effects only model. We expect the error
variances to be lower than this variance so this is an overestimate.
The variance of the gamma prior (for the precision) is controlled by
the `apar` shape parameter.

```{r}
#| label: abrainlaig
#| cache: true
apar <- 0.5
lmod <- lm(wear ~ material, abrasion)
bpar <- apar*var(residuals(lmod))
lgprior <- list(prec = list(prior="loggamma", param = c(apar,bpar)))
formula = wear ~ material+f(run, model="iid", hyper = lgprior)+f(position, model="iid", hyper = lgprior)
result <- inla(formula, family="gaussian", data=abrasion)
summary(result)
```

Results are more credible.

Compute the transforms to an SD scale for the random effect terms. Make a table of summary statistics for the posteriors:

```{r}
#| label: sumstats
sigmarun <- inla.tmarginal(function(x) 1/sqrt(exp(x)),result$internal.marginals.hyperpar[[2]])
sigmapos <- inla.tmarginal(function(x) 1/sqrt(exp(x)),result$internal.marginals.hyperpar[[3]])
sigmaepsilon <- inla.tmarginal(function(x) 1/sqrt(exp(x)),result$internal.marginals.hyperpar[[1]])
restab=sapply(result$marginals.fixed, function(x) inla.zmarginal(x,silent=TRUE))
restab=cbind(restab, inla.zmarginal(sigmarun,silent=TRUE))
restab=cbind(restab, inla.zmarginal(sigmapos,silent=TRUE))
restab=cbind(restab, inla.zmarginal(sigmaepsilon,silent=TRUE))
colnames(restab) = c("mu","B -- A","C -- A","D -- A","run","position","epsilon")
data.frame(restab) |> kable()
```

Also construct a plot the SD posteriors:

```{r}
#| label: plotsdsab
ddf <- data.frame(rbind(sigmarun,sigmapos,sigmaepsilon),errterm=gl(3,nrow(sigmarun),labels = c("run","position","epsilon")))
ggplot(ddf, aes(x,y, linetype=errterm))+geom_line()+xlab("wear")+ylab("density")+xlim(0,35)
```

Posteriors look OK although no weight given to smaller values.

## Penalized Complexity Prior

In [Simpson et al (2015)](http://arxiv.org/abs/1403.4630v3), penalized complexity priors are proposed. This
requires that we specify a scaling for the SDs of the random effects. We use the SD of the residuals
of the fixed effects only model (what might be called the base model in the paper) to provide this scaling.

```{r}
#| label: abrainlapc
#| cache: true
lmod <- lm(wear ~ material, abrasion)
sdres <- sd(residuals(lmod))
pcprior <- list(prec = list(prior="pc.prec", param = c(3*sdres,0.01)))
formula = wear ~ material+f(run, model="iid", hyper = pcprior)+f(position, model="iid", hyper = pcprior)
result <- inla(formula, family="gaussian", data=abrasion)
summary(result)
```

Compute the summaries as before:

```{r}
#| ref.label: sumstats
```

Make the plots:

```{r}
#| label: abrapc
#| ref.label: plotsdsab
```

Posteriors put more weight on lower values compared to gamma prior.

# STAN

[STAN](https://mc-stan.org/) performs Bayesian inference using
MCMC. I use `cmdstanr` to access Stan from R.

You see below the Stan code to fit our model. Rmarkdown allows the use
of Stan chunks (elsewhere I have R chunks). The chunk header looks
like this. 

STAN chunk will be compiled to 'mod'. Chunk header is:
```
cmdstan, output.var="mod", override = FALSE
```

```{cmdstan, output.var="mod", override = FALSE}
/*
Latin square style design
*/
data {
  int<lower=0> N;
  int<lower=0> Nt;
  array[N] int<lower=1,upper=Nt> treat;
  array[N] int<lower=1,upper=Nt> blk1;
  array[N] int<lower=1,upper=Nt> blk2;
  array[N] real y;
  real<lower=0> sdscal;
}
parameters {
  vector[Nt] eta1;
  vector[Nt] eta2;
  vector[Nt] trt;
  real<lower=0> sigmab1;
  real<lower=0> sigmab2;
  real<lower=0> sigmaeps;
}
transformed parameters {
  vector[Nt] bld1;
  vector[Nt] bld2;
  vector[N] yhat;

  bld1 = sigmab1 * eta1;
  bld2 = sigmab2 * eta2;

  for (i in 1:N)
    yhat[i] = trt[treat[i]] + bld1[blk1[i]] + bld2[blk2[i]];

}
model {
  eta1 ~ normal(0, 1);
  eta2 ~ normal(0, 1);
  sigmab1 ~ cauchy(0, 2.5*sdscal);
  sigmab2 ~ cauchy(0, 2.5*sdscal);
  sigmaeps ~ cauchy(0, 2.5*sdscal);

  y ~ normal(yhat, sigmaeps);
}
```

We have used uninformative priors for the fixed effects and half-cauchy priors for the three variances. We view the code here:

Prepare data in a format consistent with the command file. Needs to be a list:

```{r}
sdscal <- sd(residuals(lm(wear ~ material, abrasion)))
abrdat <- list(N=16, Nt=4, treat=as.numeric(abrasion$material), blk1=as.numeric(abrasion$run), blk2=as.numeric(abrasion$position), y=abrasion$wear, sdscal=sdscal)
```

Do the MCMC sampling:

```{r}
fit <- mod$sample(
  data = abrdat, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 0 # don't print updates
)
```


We have not used an overall mean. If we want an overall mean
parameter, we have to set up dummy variables. We can do this but it
requires more work.


## Diagnostics

Extract the draws into a convenient dataframe format:

```{r}
draws_df <- fit$draws(format = "df")
```


For the error SD:

```{r}
#| label: abrasigmab1diag
ggplot(draws_df,
       aes(x=.iteration,y=sigmab1,color=factor(.chain))) + geom_line() +
  labs(color = 'Chain', x="Iteration")
```

Looks OK

For the block two (position) SD:

```{r}
#| label: abrasigmab2diag
ggplot(draws_df,
       aes(x=.iteration,y=sigmab2,color=factor(.chain))) + geom_line() +
  labs(color = 'Chain', x="Iteration")
```

Everything looks reasonable.

## Output Summary

```{r}
parsint = c("trt","sigmaeps","sigmab1","sigmab2")
fit$summary(parsint)
```

The effective sample sizes are a bit low so we might want to rerun this with more iterations
if we care about the tails in particular.

## Posterior Distributions

We can use extract to get at various components of the STAN fit. First consider the SDs for random components:

```{r}
#| label: abrapostsig
sdf = stack(draws_df[,parsint[-1]])
colnames(sdf) = c("wear","SD")
levels(sdf$SD) = parsint[-1]
ggplot(sdf, aes(x=wear,color=SD)) + geom_density() +xlim(0,60)
```

As usual the error SD distribution is a bit more concentrated. We can see
some weight at zero for the random effects in contrast to the INLA posteriors.

Now the treatment effects:


```{r}
#| label: abraposttrt
sdf = stack(draws_df[,startsWith(colnames(draws_df),"trt")])
colnames(sdf) = c("wear","trt")
levels(sdf$trt) = LETTERS[1:4]
ggplot(sdf, aes(x=wear,color=trt)) + geom_density() 
```

We can see that material A shows some separation from the other levels.

# BRMS

[BRMS](https://paul-buerkner.github.io/brms/) stands for Bayesian Regression Models with STAN. It provides a convenient wrapper to STAN functionality. We specify the model as in `lmer()` above.
I have used more than the standard number of iterations because this reduces some problems
and does not cost much computationally.


```{r}
#| label: brmfit
#| cache: true
bmod <- brm(wear ~ material + (1|run) + (1|position), data=abrasion,iter=10000, cores=4, backend = "cmdstanr", refresh = 0, silent = 2)
```

We get some minor warnings. We can obtain some posterior densities and diagnostics with:

```{r}
#| label: abrabrmsdiag
plot(bmod, variable = "^s", regex=TRUE)
```

We have chosen only the random effect hyperparameters since this is
where problems will appear first. Looks OK. We can see some weight
is given to values of the random effect SDs close to zero.

We can look at the STAN code that `brms` used with:

```{r}
stancode(bmod)
```

We see that `brms` is using student t distributions with 3 degrees of
freedom for the priors. For the three error SDs, this will be truncated at
zero to form half-t distributions. You can get a more explicit description
of the priors with `prior_summary(bmod)`. These are qualitatively similar to the
the PC prior used in the INLA fit. 

We examine the fit:

```{r}
summary(bmod)
```

The results are consistent with those seen previously.

# MGCV

It is possible to fit some GLMMs within the GAM framework of the `mgcv`
package. An explanation of this can be found in this 
[blog](https://fromthebottomoftheheap.net/2021/02/02/random-effects-in-gams/)


```{r}
gmod = gam(wear ~ material + s(run,bs="re") + s(position,bs="re"),
           data=abrasion, method="REML")
```

and look at the summary output:

```{r}
summary(gmod)
```

We get the fixed effect estimates.
We also get tests on the random effects (as described in this [article](https://doi.org/10.1093/biomet/ast038). The hypothesis of no variation
is rejected for both the run and the position. This is consistent
with earlier findings.

We can get an estimate of the operator and error SD:

```{r}
gam.vcomp(gmod)
```

The point estimates are the same as the REML estimates from `lmer` earlier.
The confidence intervals are different. A bootstrap method was used for
the `lmer` fit whereas `gam` is using an asymptotic approximation resulting
in substantially different results. Given the problems of parameters on
the boundary present in this example, the bootstrap results appear more
trustworthy.

The random effect estimates for the fields can be found with:

```{r}
coef(gmod)
```

# GINLA

In [Wood (2019)](https://doi.org/10.1093/biomet/asz044), a
simplified version of INLA is proposed. The first
construct the GAM model without fitting and then use
the `ginla()` function to perform the computation.

```{r}
gmod = gam(wear ~ material + s(run,bs="re") + s(position,bs="re"),
           data=abrasion, fit = FALSE)
gimod = ginla(gmod)
```

We get the posterior density for the intercept as:

```{r}
#| label: abraginlaint
plot(gimod$beta[1,],gimod$density[1,],type="l",xlab="yield",ylab="wear")
```

and for the material effects as:

```{r}
#| label: abraginlalmat
xmat = t(gimod$beta[2:4,])
ymat = t(gimod$density[2:4,])
matplot(xmat, ymat,type="l",xlab="wear",ylab="density")
legend("right",paste0("Material",LETTERS[2:4]),col=1:3,lty=1:3)
```

We can see some overlap between the effects but clear separation from zero.

The run effects are:

```{r}
#| label: abraginlalrun
xmat = t(gimod$beta[5:8,])
ymat = t(gimod$density[5:8,])
matplot(xmat, ymat,type="l",xlab="wear",ylab="density")
legend("right",paste0("run",1:4),col=1:4,lty=1:4)
```

All the run effects overlap with zero but runs 3 and 4 are more distinct than 1 and 2.

The position effects are:

```{r}
#| label: abraginlalpos
xmat = t(gimod$beta[9:12,])
ymat = t(gimod$density[9:12,])
matplot(xmat, ymat,type="l",xlab="wear",ylab="density")
legend("right",paste0("position",1:4),col=1:4,lty=1:4)
```

Here positions 1 and 2 are more distinct in their effects.

It is not straightforward to obtain the posterior densities of
the hyperparameters. 

# Discussion

See the [Discussion of the single random effect model](pulp.md#Discussion) for
general comments. 

- All but the INLA analysis have some ambiguity about whether there is much difference in the
run and position effects. In the mixed effect model, the effects are just statistically significant
while the Bayesian analyses also suggest these effects have some impact while still expressing
some chance that they do not. The INLA analysis does not give any weight to the no effect claim.

- None of the analysis had any problem with the crossed effects.

- There were no major computational issue with the analyses (in contrast with some of
the other examples)

- August 2024 update: Rerunning the code on updated versions of the packages
resulted in some minor changes in the (Bayesian) output although this can
likely be attributed to random number generation in MCMC.

# Package version info

```{r}
sessionInfo()
```



