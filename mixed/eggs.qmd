---
title: Nested Design
author: "[Julian Faraway](https://julianfaraway.github.io/)"
date: "`r format(Sys.time(), '%d %B %Y')`"
format: 
  gfm:
    toc: true
---

```{r}
#| label: global_options
#| include: false
knitr::opts_chunk$set(comment=NA, 
                      echo = TRUE,
                      fig.path="figs/",
                      dev = 'svglite',  
                      fig.ext = ".svg",
                      warning=FALSE, 
                      message=FALSE)
knitr::opts_knit$set(global.par = TRUE)
```

```{r}
#| label: graphopts
#| include: false
par(mgp=c(1.5,0.5,0), mar=c(3.1,3.1,0.1,0), pch=20)
ggplot2::theme_set(ggplot2::theme_bw())
```

See the [introduction](index.md) for an overview. 

This example is discussed in more detail in my book
[Extending the Linear Model with R](https://julianfaraway.github.io/faraway/ELM/)

Required libraries:

```{r}
library(faraway)
library(ggplot2)
library(lme4)
library(pbkrtest)
library(RLRsim)
library(INLA)
library(knitr)
library(cmdstanr)
register_knitr_engine(override = FALSE)
library(brms)
library(mgcv)
```

# Data

When the levels of one factor vary only within the levels of another
factor, that factor is said to be *nested*. Here is an example to illustrate nesting. Consistency between laboratory tests is important and yet the results may depend on who did the test and where the test was performed. In an experiment to
test levels of consistency, a large jar of dried egg powder was
divided up into a number of samples. Because the powder was
homogenized, the fat content of the samples is the same, but this fact
is withheld from the laboratories. Four samples were sent to each of
six laboratories.  Two of the samples were labeled as G and two as H,
although in fact they were identical.  The laboratories were
instructed to give two samples to two different technicians. The
technicians were then instructed to divide their samples into two
parts and measure the fat content of each.  So each laboratory
reported eight measures, each technician four measures, that is, two replicated
measures on each of two samples.

Load in and plot the data:

```{r}
#| label: eggplot
data(eggs, package="faraway")
summary(eggs)
ggplot(eggs, aes(y=Fat, x=Lab, color=Technician, shape=Sample)) + geom_point(position = position_jitter(width=0.1, height=0.0))
```

# Mixed Effect Model

The model is $$y_{ijkl} = \mu + L_i + T_{ij} + S_{ijk} + \epsilon_{ijkl}$$
where laboratories (L), technicians (T) and samples (S) are all random effects:

```{r}
cmod = lmer(Fat ~ 1 + (1|Lab) + (1|Lab:Technician) +  (1|Lab:Technician:Sample), data=eggs)
faraway::sumary(cmod)
```

Is there a difference between samples? The `exactRLRT` function requires 
not only the specification of a null model without the random effect of interest
but also one where only that random effect is present. Note that because
of the way the samples are coded, we need to specify this a three-way interaction.
Otherwise `G` from one lab would be linked to `G` from another lab (which is
not the case).

```{r}
cmodr <- lmer(Fat ~ 1 + (1|Lab) + (1|Lab:Technician), data=eggs)
cmods <- lmer(Fat ~ 1 + (1|Lab:Technician:Sample), data=eggs)
exactRLRT(cmods, cmod, cmodr)
```

We can remove the sample random effect from the model. But consider
the confidence intervals:

```{r}
#| label: eggsconfint
#| cache: true
confint(cmod, method="boot")
```

We see that all three random effects include zero at the lower end, indicating
that we might equally have disposed of the lab or technician random effects first.
There is considerable uncertainty in the apportioning of variation due the three
effects.

# INLA

Integrated nested Laplace approximation is a method of Bayesian computation
which uses approximation rather than simulation. More can be found
on this topic in [Bayesian Regression Modeling with INLA](http://julianfaraway.github.io/brinla/) and the 
[chapter on GLMMs](https://julianfaraway.github.io/brinlabook/chaglmm.html)

Use the most recent computational methodology:


```{r}
inla.setOption(inla.mode="experimental")
inla.setOption("short.summary",TRUE)
```

Need to construct unique labels for
nested factor levels. Don't really care which technician and sample is
which otherwise would take more care with the labeling.

```{r}
eggs$labtech <- factor(paste0(eggs$Lab,eggs$Technician))
eggs$labtechsamp <- factor(paste0(eggs$Lab,eggs$Technician,eggs$Sample))
```

```{r}
#| label: eggsinladef
#| cache: true
formula <- Fat ~ 1 + f(Lab, model="iid") + f(labtech, model="iid") + f(labtechsamp, model="iid")
result <- inla(formula, family="gaussian", data=eggs)
summary(result)
```

The lab and sample precisions look far too high. Need to change the default prior

## Informative Gamma priors on the precisions

Now try more informative gamma priors for the precisions. Define it so
the mean value of gamma prior is set to the inverse of the variance of
the residuals of the fixed-effects only model. We expect the error
variances to be lower than this variance so this is an overestimate.
The variance of the gamma prior (for the precision) is controlled by
the `apar` shape parameter in the code.

```{r}
#| label: eggsinlaig
#| cache: true
apar <- 0.5
bpar <- apar*var(eggs$Fat)
lgprior <- list(prec = list(prior="loggamma", param = c(apar,bpar)))
formula = Fat ~ 1+f(Lab, model="iid", hyper = lgprior)+f(labtech, model="iid", hyper = lgprior)+f(labtechsamp, model="iid", hyper = lgprior)
result <- inla(formula, family="gaussian", data=eggs)
summary(result)
```

Looks more credible.

Compute the transforms to an SD scale for the field and error. Make a table of summary statistics for the posteriors:

```{r}
#| label: sumstats
sigmaLab <- inla.tmarginal(function(x) 1/sqrt(exp(x)),result$internal.marginals.hyperpar[[2]])
sigmaTech <- inla.tmarginal(function(x) 1/sqrt(exp(x)),result$internal.marginals.hyperpar[[3]])
sigmaSample <- inla.tmarginal(function(x) 1/sqrt(exp(x)),result$internal.marginals.hyperpar[[4]])
sigmaepsilon <- inla.tmarginal(function(x) 1/sqrt(exp(x)),result$internal.marginals.hyperpar[[1]])
restab=sapply(result$marginals.fixed, function(x) inla.zmarginal(x,silent=TRUE))
restab=cbind(restab, inla.zmarginal(sigmaLab,silent=TRUE))
restab=cbind(restab, inla.zmarginal(sigmaTech,silent=TRUE))
restab=cbind(restab, inla.zmarginal(sigmaSample,silent=TRUE))
restab=cbind(restab, inla.zmarginal(sigmaepsilon,silent=TRUE))
colnames(restab) = c("mu","Lab","Technician","Sample","epsilon")
data.frame(restab)
```

Also construct a plot the SD posteriors:

```{r}
#| label: plotsdseggs
ddf <- data.frame(rbind(sigmaLab,sigmaTech,sigmaSample,sigmaepsilon),errterm=gl(4,nrow(sigmaLab),labels = c("Lab","Tech","Samp","epsilon")))
ggplot(ddf, aes(x,y, linetype=errterm))+geom_line()+xlab("Fat")+ylab("density")+xlim(0,0.25)
```

Posteriors look OK. Notice that they are all well bounded away from zero.

## Penalized Complexity Prior

In [Simpson et al (2015)](http://arxiv.org/abs/1403.4630v3), penalized complexity priors are proposed. This
requires that we specify a scaling for the SDs of the random effects. We use the SD of the residuals
of the fixed effects only model (what might be called the base model in the paper) to provide this scaling.

```{r}
#| label: eggsinlapc
#| cache: true
sdres <- sd(eggs$Fat)
pcprior <- list(prec = list(prior="pc.prec", param = c(3*sdres,0.01)))
formula = Fat ~ 1+f(Lab, model="iid", hyper = pcprior)+f(labtech, model="iid", hyper = pcprior)+f(labtechsamp,model="iid", hyper = pcprior)
result <- inla(formula, family="gaussian", data=eggs, control.family=list(hyper=pcprior))
summary(result)
```

Compute the summaries as before:

```{r}
#| ref.label: sumstats
```

Make the plots:

```{r}
#| label: eggspc
#| ref.label: plotsdseggs
```

Posteriors have generally smaller values for the three random effects and 
the possibility of values closer to zero is given greater weight.

# STAN

[STAN](https://mc-stan.org/) performs Bayesian inference using
MCMC. I use `cmdstanr` to access Stan from R.

You see below the Stan code to fit our model. Rmarkdown allows the use
of Stan chunks (elsewhere I have R chunks). The chunk header looks
like this. 

STAN chunk will be compiled to 'mod'. Chunk header is:
```
cmdstan, output.var="mod", override = FALSE
```

```{cmdstan, output.var="mod", override = FALSE}
data {
     int<lower=0> Nobs;
     int<lower=0> Nlev1;
     int<lower=0> Nlev2;
     int<lower=0> Nlev3;
     array[Nobs] real y;
     array[Nobs] int<lower=1,upper=Nlev1> levind1;
     array[Nobs] int<lower=1,upper=Nlev2> levind2;
     array[Nobs] int<lower=1,upper=Nlev3> levind3;
     real<lower=0> sdscal;
}
parameters {
           real mu;
           real<lower=0> sigmalev1;
           real<lower=0> sigmalev2;
           real<lower=0> sigmalev3;
           real<lower=0> sigmaeps;

           vector[Nlev1] eta1;
           vector[Nlev2] eta2;
           vector[Nlev3] eta3;
}
transformed parameters {
  vector[Nlev1] ran1;
  vector[Nlev2] ran2;
  vector[Nlev3] ran3;
  vector[Nobs] yhat;

  ran1  = sigmalev1 * eta1;
  ran2  = sigmalev2 * eta2;
  ran3  = sigmalev3 * eta3;

  for (i in 1:Nobs)
    yhat[i] = mu+ran1[levind1[i]]+ran2[levind2[i]]+ran3[levind3[i]];

}
model {
  eta1 ~ normal(0, 1);
  eta2 ~ normal(0, 1);
  eta3 ~ normal(0, 1);
  sigmalev1 ~ cauchy(0, 2.5*sdscal);
  sigmalev2 ~ cauchy(0, 2.5*sdscal);
  sigmalev3 ~ cauchy(0, 2.5*sdscal);
  sigmaeps ~ cauchy(0, 2.5*sdscal);
  y ~ normal(yhat, sigmaeps);
}
```

```{r}
levind1 <- as.numeric(eggs$Lab)
levind2 <- as.numeric(eggs$labtech)
levind3 <- as.numeric(eggs$labtechsamp)
sdscal <- sd(eggs$Fat)
eggdat <- list(Nobs=nrow(eggs),
               Nlev1=max(levind1),
               Nlev2=max(levind2),
               Nlev3=max(levind3),
               y=eggs$Fat,
               levind1=levind1,
               levind2=levind2,
               levind3=levind3,
               sdscal=sdscal)
```

Do the MCMC sampling:

```{r}
fit <- mod$sample(
  data = eggdat, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500 # print update every 500 iters
)
```

## Diagnostics

Extract the draws into a convenient dataframe format:

```{r}
draws_df <- fit$draws(format = "df")
```


For the error SD:

```{r}
#| label: eggssigmaeps
ggplot(draws_df,
       aes(x=.iteration,y=sigmaeps,color=factor(.chain))) + geom_line() +
  labs(color = 'Chain', x="Iteration")
```

Looks OK


For the Lab SD

```{r}
#| label: eggssigmalev1
ggplot(draws_df,
       aes(x=.iteration,y=sigmalev1,color=factor(.chain))) + geom_line() +
  labs(color = 'Chain', x="Iteration")
```

Looks OK

For the technician SD

```{r}
#| label: eggssigmalev2
ggplot(draws_df,
       aes(x=.iteration,y=sigmalev2,color=factor(.chain))) + geom_line() +
  labs(color = 'Chain', x="Iteration")
```

For the sample SD

```{r}
#| label: reggssigmalev3
ggplot(draws_df,
       aes(x=.iteration,y=sigmalev3,color=factor(.chain))) + geom_line() +
  labs(color = 'Chain', x="Iteration")
```

All these are satisfactory.


## Output summaries

Display the parameters of interest:

```{r}
fit$summary(c("mu","sigmalev1","sigmalev2","sigmalev3","sigmaeps"))
```

About what we expect:

## Posterior Distributions

We can use extract to get at various components of the STAN fit.

```{r}
#| label: eggsstanhypsd
sdf = stack(draws_df[,c("sigmalev1","sigmalev2","sigmalev3","sigmaeps")])
colnames(sdf) = c("Fat","SD")
levels(sdf$SD) = c("Lab","Technician","Sample","Error")
ggplot(sdf, aes(x=Fat,color=SD)) + geom_density() +xlim(0,0.3)
```

We see that the error SD can be localized much more than the other SDs. The technician SD looks to be the largest of the three. We see non-zero
density at zero in contrast with the INLA posteriors.

# BRMS

[BRMS](https://paul-buerkner.github.io/brms/) stands for Bayesian Regression Models with STAN. It provides
a convenient wrapper to STAN functionality.

The form of the model specification is important in this example. If we use
`Fat ~ 1 + (1|Lab) + (1|Lab:Technician) +  (1|Lab:Technician:Sample)` as
in the `lmer` fit earlier, we get poor convergence whereas the supposedly
equivalent specification below does far better. In the form below, the
nesting is signalled by the form of the model specification which
may be essential to achieve the best results.

```{r}
#| label: brmfit
#| cache: true
bmod <- brm(Fat ~ 1 + (1|Lab/Technician/Sample), data=eggs,iter=10000, cores=4,silent=2,backend = "cmdstanr")
```

We get some warnings. We can obtain some posterior densities and diagnostics with:

```{r}
#| label: eggsbrmsdiag
plot(bmod, variable = "^s", regex=TRUE)
```

We have chosen only the random effect hyperparameters since this is
where problems will appear first. Looks OK. We can see some weight
is given to values of the random effect SDs close to zero.

We can look at the STAN code that `brms` used with:

```{r}
stancode(bmod)
```

We see that `brms` is using student t distributions with 3 degrees of
freedom for the priors. For the two error SDs, this will be truncated at
zero to form half-t distributions. You can get a more explicit description
of the priors with `prior_summary(bmod)`. These are qualitatively similar to the
the PC prior used in the INLA fit. 

We examine the fit:

```{r}
summary(bmod)
```

The results are consistent with those seen previously.

# MGCV

It is possible to fit some GLMMs within the GAM framework of the `mgcv`
package. An explanation of this can be found in this 
[blog](https://fromthebottomoftheheap.net/2021/02/02/random-effects-in-gams/)


```{r}
gmod = gam(Fat ~ 1 + s(Lab,bs="re") + s(Lab,Technician,bs="re") + 
             s(Lab,Technician,Sample,bs="re"),
           data=eggs, method="REML")
```

and look at the summary output:

```{r}
summary(gmod)
```

We get the fixed effect estimate.
We also get tests on the random effects (as described in this [article](https://doi.org/10.1093/biomet/ast038). The hypothesis of no variation
is not rejected for any of the three sources of variation. This is consistent
with earlier findings.

We can get an estimate of the operator and error SD:

```{r}
gam.vcomp(gmod)
```

The point estimates are the same as the REML estimates from `lmer` earlier.
The confidence intervals are different. A bootstrep method was used for
the `lmer` fit whereas `gam` is using an asymptotic approximation resulting
in substantially different results. Given the problems of parameters on
the boundary present in this example, the bootstrap results appear more
trustworthy.

The random effect estimates for the fields can be found with:

```{r}
coef(gmod)
```

although these have not been centered in contrast with that found from
the `lmer` fit.


# GINLA

In [Wood (2019)](https://doi.org/10.1093/biomet/asz044), a
simplified version of INLA is proposed. The first
construct the GAM model without fitting and then use
the `ginla()` function to perform the computation.

```{r}
gmod = gam(Fat ~ 1 + s(Lab,bs="re") + s(Lab,Technician,bs="re") + 
             s(Lab,Technician,Sample,bs="re"),
           data=eggs, fit = FALSE)
gimod = ginla(gmod)
```

We get the posterior density for the intercept as:

```{r}
#| label: eggsginlaint
plot(gimod$beta[1,],gimod$density[1,],type="l",xlab="yield",ylab="fat")
```

and for the laboratory effects as:

```{r}
#| label: eggsginlaleff
xmat = t(gimod$beta[2:7,])
ymat = t(gimod$density[2:7,])
matplot(xmat, ymat,type="l",xlab="fat",ylab="density")
legend("right",paste0("Lab",1:6),col=1:6,lty=1:6)
```

We can see the first lab tends to be higher but still substantial
overlap with the other labs.

The random effects for the technicians are:

```{r}
#| label: eggsginlateff
sel = 8:19
xmat = t(gimod$beta[sel,])
ymat = t(gimod$density[sel,])
matplot(xmat, ymat,type="l",xlab="fat",ylab="density")
legend("right",row.names(coef(cmod)[[2]]),col=1:length(sel),lty=1:length(sel))
```

There are a couple of technicians which stick out from the others. Not overwhelming
evidence that they are different but certainly worth further investigation.

There are too many of the sample random effects to make plotting helpful.

It is not straightforward to obtain the posterior densities of
the hyperparameters. 

# Discussion

See the [Discussion of the single random effect model](pulp.md#Discussion) for
general comments. 

- As with some of the other analyses, we see that the INLA-produced posterior
densities for the random effect SDs are well-bounded away from zero. We
see that the choice of prior does make an important difference and that
the default choice is a clear failure.

- The default STAN priors produce a credible result and posteriors do
give some weight to values close to zero. There is no ground truth here
but given the experience in the `lmer` analysis, there does appear to be
some suggestion that any of the three sources of variation could be very
small. INLA is the odd-one-out in this instance.

- The `mgcv` based analysis is mostly the same as the `lme4` fit excepting
the confidence intervals where a different method has been used.

- The `ginla` does not readily produce posterior densities for the hyperparameters
so we cannot compare on that basis. The other posteriors were produced very rapidly.

# Package version info

```{r}
sessionInfo()
```



